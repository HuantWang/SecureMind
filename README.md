[![Maintenance](https://img.shields.io/badge/Maintained%3F-YES-green.svg)](https://github.com/HuantWang/SUPERSONIC/graphs/commit-activity)
[![License CC-BY-4.0](https://img.shields.io/badge/License-CC%20BY%204.0-blue.svg)](https://github.com/HuantWang/SUPERSONIC/blob/master/LICENSE)
[![Documentation Status](https://readthedocs.org/projects/supersonic/badge/?version=latest)](https://supersonic.readthedocs.io/en/latest/?badge=latest)

<div align="center">
 <img src="./logo.png" alt="1683381967744" width=30% height=20%>
</div>
<p align="center" >
  <i>A Framework for Benchmarking Large Language Models in Memory Bug Detection and Repair</i>
</p>

<p align="center">
  <i>

  </i>
</p>


## Introduction

SecureMind: SecureMind provides a customizable and user-friendly interface for defining test plans as Python
scripts, which are then executed to automatically download
and prepare data to benchmark LLMs automatically across a
wide range of evaluation metrics.

## Installation

Prom builds upon:

-	Python 3.10
-	SecLLMHolmes

The system was tested on the following operating systems:

- Ubuntu 20.04


See [INSTALL.md](INSTALL.md) for further details.

## Data

Data are available at [here](./datasets/README.md).

## Contributing

We welcome contributions to Prom. If you are interested in contributing please see
[this document](./CONTRIBUTING.md).





